{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f16b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_obs = '/Users/eva/Documents/Work/promotion/cnn/dropbox_data/observation/'\n",
    "dir_predictors_train = '/Users/eva/Documents/Work/promotion/cnn/dropbox_data/predictors/train/'\n",
    "dir_predictors_test = '/Users/eva/Documents/Work/promotion/cnn/dropbox_data/predictors/test/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4cb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "obs_train = xr.open_dataset(dir_obs + 'obs_precip_train.nc') \n",
    "obs_test = xr.open_dataset(dir_obs + 'obs_precip_test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ebdd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictors for training\n",
    "kindx_train = xr.open_dataset(dir_predictors_train + 'kindx_2000_2017.nc') \n",
    "corr1_train = xr.open_dataset(dir_predictors_train + 'corr_lag1_train.nc') \n",
    "corr2_train = xr.open_dataset(dir_predictors_train + 'corr_lag2_train.nc') \n",
    "corr3_train =xr.open_dataset(dir_predictors_train + 'corr_lag3_train.nc')\n",
    "pw_train = xr.open_dataset(dir_predictors_train + 'tcwv_2000_2017.nc') \n",
    "cape_train = xr.open_dataset(dir_predictors_train + 'cape_2000_2017.nc') \n",
    "d2m_train = xr.open_dataset(dir_predictors_train + 'd2m_2000_2017.nc') \n",
    "t3_train = xr.open_dataset(dir_predictors_train + 't300_2000_2017.nc') \n",
    "t5_train = xr.open_dataset(dir_predictors_train + 't500_2000_2017.nc') \n",
    "t8_train = xr.open_dataset(dir_predictors_train + 't800_2000_2017.nc') \n",
    "rh5_train = xr.open_dataset(dir_predictors_train + 'rh500_2000_2017.nc') \n",
    "rh8_train = xr.open_dataset(dir_predictors_train + 'rh800_2000_2017.nc') \n",
    "toa_train = xr.open_dataset(dir_predictors_train + 'toa_0pm_2000_2017.nc') \n",
    "geodiff_train = xr.open_dataset(dir_predictors_train + 'geodiff_2000_2017.nc') \n",
    "cc_train = xr.open_dataset(dir_predictors_train + 'cloudcover_2000_2017.nc') \n",
    "clwc_train = xr.open_dataset(dir_predictors_train + 'cloudwater_2000_2017.nc') \n",
    "ciwc5_train = xr.open_dataset(dir_predictors_train + 'cloudice500_2000_2017.nc') \n",
    "temp_train = xr.open_dataset(dir_predictors_train + 't2m_2000_2017.nc') \n",
    "g5_train = xr.open_dataset(dir_predictors_train + 'geo500_2000_2017.nc') \n",
    "g7_train = xr.open_dataset(dir_predictors_train + 'geo700_2000_2017.nc')\n",
    "sh7_train = xr.open_dataset(dir_predictors_train + 'specifichum700_2000_2017.nc')\n",
    "vo7_train = xr.open_dataset(dir_predictors_train + 'relvor700_2000_2017.nc')\n",
    "cin_train = xr.open_dataset(dir_predictors_train + 'cin_2000_2017.nc') \n",
    "shear_train = xr.open_dataset(dir_predictors_train + 'shear925_600_2000_2017.nc')\n",
    "#sp_train = xr.open_dataset(dir_predictors_train + 'surfpressure_4pm_2000_2017.nc')  \n",
    "sp_train = xr.open_dataset(dir_predictors_train + 'surfpressure_2000_2017.nc')  \n",
    "#geo850_train = xr.open_dataset(dir_predictors_train + 'geo850_4pm_2000_2017.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30d4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictors for testing\n",
    "kindx_test = xr.open_dataset(dir_predictors_test + 'kindx_2018_2019.nc') \n",
    "corr1_test = xr.open_dataset(dir_predictors_test + 'corr_lag1_test.nc') \n",
    "corr2_test = xr.open_dataset(dir_predictors_test + 'corr_lag2_test.nc') \n",
    "corr3_test =xr.open_dataset(dir_predictors_test + 'corr_lag3_test.nc')\n",
    "pw_test = xr.open_dataset(dir_predictors_test + 'tcwv_2018_2019.nc') \n",
    "cape_test = xr.open_dataset(dir_predictors_test + 'cape_2018_2019.nc') \n",
    "d2m_test = xr.open_dataset(dir_predictors_test + 'd2m_2018_2019.nc')\n",
    "t3_test = xr.open_dataset(dir_predictors_test + 't300_2018_2019.nc') \n",
    "t5_test = xr.open_dataset(dir_predictors_test + 't500_2018_2019.nc') \n",
    "t8_test = xr.open_dataset(dir_predictors_test + 't800_2018_2019.nc') \n",
    "rh5_test = xr.open_dataset(dir_predictors_test + 'rh500_2018_2019.nc') \n",
    "rh8_test = xr.open_dataset(dir_predictors_test + 'rh800_2018_2019.nc') \n",
    "toa_test = xr.open_dataset(dir_predictors_test + 'toa_0pm_2018_2019.nc') \n",
    "geodiff_test = xr.open_dataset(dir_predictors_test + 'geodiff_2018_2019.nc') \n",
    "cc_test = xr.open_dataset(dir_predictors_test + 'cloudcover_2018_2019.nc') \n",
    "clwc_test = xr.open_dataset(dir_predictors_test + 'cloudwater_2018_2019.nc') \n",
    "ciwc5_test = xr.open_dataset(dir_predictors_test + 'cloudice500_2018_2019.nc') \n",
    "temp_test = xr.open_dataset(dir_predictors_test + 't2m_2018_2019.nc') \n",
    "g5_test= xr.open_dataset(dir_predictors_test + 'geo500_2018_2019.nc') \n",
    "g7_test = xr.open_dataset(dir_predictors_test + 'geo700_2018_2019.nc')\n",
    "sh7_test = xr.open_dataset(dir_predictors_test + 'specifichum700_2018_2019.nc')\n",
    "vo7_test = xr.open_dataset(dir_predictors_test + 'relvor700_2018_2019.nc')\n",
    "cin_test = xr.open_dataset(dir_predictors_test + 'cin_2018_2019.nc') \n",
    "shear_test = xr.open_dataset(dir_predictors_test + 'shear925_600_2018_2019.nc')\n",
    "#sp_train = xr.open_dataset(dir_predictors_train + 'surfpressure_4pm_2000_2017.nc')  \n",
    "sp_test = xr.open_dataset(dir_predictors_test + 'surfpressure_2018_2019.nc')  \n",
    "#geo850_train = xr.open_dataset(dir_predictors_train + 'geo850_4pm_2000_2017.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f6f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = obs_train.lat.values\n",
    "lons = obs_train.lon.values\n",
    "lats = lats[0:19]\n",
    "lons = lons[43:104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdfce26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test):\n",
    "    if np.all((train == 0)):\n",
    "        return train, test\n",
    "    else:\n",
    "        scale_std = np.std(train)\n",
    "        if scale_std == 0:\n",
    "            scale_mean = np.mean(train)\n",
    "            return train-scale_mean, test-scale_mean\n",
    "        else:\n",
    "            scale_mean = np.mean(train)\n",
    "            return (train - scale_mean) / scale_std, (test - scale_mean) / scale_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e79e9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor for time\n",
    "test_t_0  = pd.date_range(start='12/01/2017T00', end='11/30/2019T00')\n",
    "train_t_0 = pd.date_range(start='12/01/2000T00', end='11/30/2017T00')\n",
    "\n",
    "dayofyears_train = train_t_0.dayofyear.to_numpy() - 1\n",
    "dayofyears_test = test_t_0.dayofyear.to_numpy() - 1\n",
    "pred_time1 = np.sin(2 * np.pi * dayofyears_train / 365)\n",
    "pred_time2 = np.cos(2 * np.pi * dayofyears_train / 365)\n",
    "pred_time1_test = np.sin(2 * np.pi * dayofyears_test / 365)\n",
    "pred_time2_test = np.cos(2 * np.pi * dayofyears_test / 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74869844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(lat, lon):\n",
    "    kindx_train2 = kindx_train.sel(latitude=lat, longitude=lon).kx.values\n",
    "    corr1_train2 = corr1_train.sel(lat=lat, lon=lon).precip.values\n",
    "    corr2_train2 = corr2_train.sel(lat=lat, lon=lon).precip.values\n",
    "    corr3_train2 = corr3_train.sel(lat=lat, lon=lon).precip.values\n",
    "    pw_train2 = pw_train.sel(lat=lat, lon=lon).tcwv.values \n",
    "    cape_train2 = cape_train.sel(latitude=lat, longitude=lon).cape.values\n",
    "    d2m_train2 = d2m_train.sel(latitude=lat, longitude=lon).d2m.values\n",
    "    t3_train2 = t3_train.sel(latitude = lat, longitude = lon).t.values\n",
    "    t5_train2 = t5_train.sel(latitude = lat, longitude = lon).t.values\n",
    "    t8_train2 = t8_train.sel(latitude = lat, longitude = lon).t.values\n",
    "    rh5_train2 = rh5_train.sel(latitude=lat, longitude=lon).r.values\n",
    "    rh8_train2 = rh8_train.sel(latitude=lat, longitude=lon).r.values\n",
    "    toa_train2 = toa_train.sel(latitude=lat, longitude=lon).tisr.values\n",
    "    geodiff_train2 = geodiff_train.sel(latitude=lat, longitude=lon).z.values\n",
    "    cc_train2 = cc_train.sel(lat=lat, lon=lon).tcc.values\n",
    "    clwc_train2 = clwc_train.sel(lat=lat, lon=lon).tclw.values \n",
    "    ciwc5_train2 = ciwc5_train.sel(lat=lat, lon=lon).ciwc.values \n",
    "    temp_train2 = temp_train.sel(latitude = lat, longitude = lon).t2m.values\n",
    "    g5_train2 = g5_train.sel(latitude=lat, longitude=lon).z.values\n",
    "    g7_train2 = g7_train.sel(latitude=lat, longitude=lon).z.values\n",
    "    sh7_train2 = sh7_train.sel(latitude=lat, longitude=lon).q.values\n",
    "    vo7_train2 = vo7_train.sel(latitude=lat, longitude=lon).vo.values\n",
    "    cin_train2 = cin_train.sel(latitude=lat, longitude=lon).cin.values \n",
    "    shear_train2 = shear_train.sel(latitude=lat, longitude=lon).shear.values\n",
    "    sp_train2 = sp_train.sel(latitude=lat, longitude=lon).sp.values \n",
    "    \n",
    "    kindx_test2 = kindx_test.sel(latitude=lat, longitude=lon).kx.values\n",
    "    corr1_test2 = corr1_test.sel(lat=lat, lon=lon).precip.values\n",
    "    corr2_test2 = corr2_test.sel(lat=lat, lon=lon).precip.values\n",
    "    corr3_test2 = corr3_test.sel(lat=lat, lon=lon).precip.values\n",
    "    pw_test2 = pw_test.sel(lat=lat, lon=lon).tcwv.values\n",
    "    cape_test2 = cape_test.sel(latitude=lat, longitude=lon).cape.values\n",
    "    d2m_test2 = d2m_test.sel(latitude=lat, longitude=lon).d2m.values\n",
    "    t3_test2 = t3_test.sel(latitude = lat, longitude = lon).t.values\n",
    "    t5_test2 = t5_test.sel(latitude = lat, longitude = lon).t.values\n",
    "    t8_test2 = t8_test.sel(latitude = lat, longitude = lon).t.values\n",
    "    rh5_test2 = rh5_test.sel(latitude=lat, longitude=lon).r.values\n",
    "    rh8_test2 = rh8_test.sel(latitude=lat, longitude=lon).r.values\n",
    "    toa_test2 = toa_test.sel(latitude=lat, longitude=lon).tisr.values\n",
    "    geodiff_test2 = geodiff_test.sel(latitude=lat, longitude=lon).z.values\n",
    "    cc_test2 = cc_test.sel(lat=lat, lon=lon).tcc.values\n",
    "    clwc_test2 = clwc_test.sel(lat=lat, lon=lon).tclw.values\n",
    "    ciwc5_test2 = ciwc5_test.sel(lat=lat, lon=lon).ciwc.values\n",
    "    temp_test2 = temp_test.sel(latitude = lat, longitude = lon).t2m.values\n",
    "    g5_test2 = g5_test.sel(latitude=lat, longitude=lon).z.values\n",
    "    g7_test2 = g7_test.sel(latitude=lat, longitude=lon).z.values\n",
    "    sh7_test2 = sh7_test.sel(latitude=lat, longitude=lon).q.values\n",
    "    vo7_test2 = vo7_test.sel(latitude=lat, longitude=lon).vo.values\n",
    "    cin_test2 = cin_test.sel(latitude=lat, longitude=lon).cin.values\n",
    "    shear_test2 = shear_test.sel(latitude=lat, longitude=lon).shear.values\n",
    "    sp_test2 = sp_test.sel(latitude=lat, longitude=lon).sp.values\n",
    "\n",
    "    kindx_train2, kindx_test2 = normalize(kindx_train2, kindx_test2)\n",
    "    pw_train2 , pw_test2 = normalize(pw_train2 , pw_test2)\n",
    "    cape_train2, cape_test2 = normalize(cape_train2, cape_test2)\n",
    "    d2m_train2, d2m_test2 = normalize(d2m_train2, d2m_test2)\n",
    "    t3_train2, t3_test2 = normalize(t3_train2, t3_test2)\n",
    "    t5_train2, t5_test2 = normalize(t5_train2, t5_test2)\n",
    "    t8_train2, t8_test2 = normalize(t8_train2, t8_test2)\n",
    "    rh5_train2, rh5_test2 = normalize(rh5_train2, rh5_test2)\n",
    "    rh8_train2, rh8_test2 = normalize(rh8_train2, rh8_test2)\n",
    "    toa_train2, toa_test2 = normalize(toa_train2, toa_test2)\n",
    "    geodiff_train2, geodiff_test2 = normalize(geodiff_train2, geodiff_test2)\n",
    "    cc_train2, cc_test2 = normalize(cc_train2, cc_test2)\n",
    "    clwc_train2, clwc_test2 = normalize(clwc_train2, clwc_test2)\n",
    "    ciwc5_train2, ciwc5_test2 = normalize(ciwc5_train2, ciwc5_test2)\n",
    "    temp_train2, temp_test2 = normalize(temp_train2, temp_test2)\n",
    "    g5_train2, g5_test2 = normalize(g5_train2, g5_test2)\n",
    "    g7_train2, g7_test2 = normalize(g7_train2, g7_test2)\n",
    "    sh7_train2, sh7_test2 = normalize(sh7_train2, sh7_test2) \n",
    "    vo7_train2, vo7_test2 = normalize(vo7_train2, vo7_test2)\n",
    "    cin_train2, cin_test2 = normalize(cin_train2, cin_test2)\n",
    "    shear_train2, shear_test2 = normalize(shear_train2, shear_test2)\n",
    "    sp_train2, sp_test2 = normalize(sp_train2, sp_test2)\n",
    "    \n",
    "    predictors = np.vstack((np.log(corr1_train2 + 0.001), np.log(corr2_train2 + 0.001), np.log(corr3_train2 + 0.001), \n",
    "                            kindx_train2, pw_train2, cape_train2,d2m_train2,t3_train2, t5_train2, t8_train2,\n",
    "                            rh5_train2,rh8_train2,toa_train2, geodiff_train2,cc_train2,clwc_train2,\n",
    "                            ciwc5_train2,temp_train2,g5_train2, g7_train2,sh7_train2,vo7_train2, \n",
    "                            cin_train2, shear_train2, sp_train2, pred_time1, pred_time2)).T\n",
    "    predictors_test = np.vstack((np.log(corr1_test2 + 0.001), np.log(corr2_test2 + 0.001), np.log(corr3_test2 + 0.001),\n",
    "                        kindx_test2, pw_test2, cape_test2, d2m_test2, t3_test2, t5_test2, t8_test2,\n",
    "                        rh5_test2, rh8_test2, toa_test2, geodiff_test2, cc_test2, clwc_test2,\n",
    "                        ciwc5_test2, temp_test2, g5_test2, g7_test2, sh7_test2, vo7_test2,\n",
    "                        cin_test2, shear_test2, sp_test2, pred_time1_test, pred_time2_test)).T\n",
    "    return predictors, predictors_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041551c",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a7cae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n",
      "19.0\n"
     ]
    }
   ],
   "source": [
    "bs_log = np.zeros((len(lats), len(lons)))\n",
    "i = 0\n",
    "for lat in lats:\n",
    "    j = 0\n",
    "    for lon in lons:\n",
    "        grid_train = obs_train.sel(lat = lat, lon = lon).precipitationCal.values\n",
    "        grid_test = obs_test.sel(lat = lat, lon = lon).precipitationCal.values\n",
    "        predictors, predictors_test = get_preds(lat, lon)\n",
    "        obs_train_bin = grid_train > 0.2\n",
    "        obs_test_bin = grid_test > 0.2\n",
    "        if np.sum(obs_train_bin) == 0:\n",
    "            probs_rain = obs_train_bin\n",
    "        else:\n",
    "            clf = LogisticRegression(max_iter=300).fit(predictors, obs_train_bin)\n",
    "            probs_rain = clf.predict_proba(predictors_test)[:, 1]\n",
    "        bs_log[i, j] = np.mean((probs_rain - obs_test_bin) ** 2)\n",
    "        j = j+1\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb2de5",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db70788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a318e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_log = np.zeros((len(lats), len(lons)))\n",
    "i = 0\n",
    "for lat in lats:\n",
    "    j = 0\n",
    "    for lon in lons:\n",
    "        grid_train = obs_train.sel(lat = lat, lon = lon).precipitationCal.values\n",
    "        grid_test = obs_test.sel(lat = lat, lon = lon).precipitationCal.values\n",
    "        predictors, predictors_test = get_preds(lat, lon)\n",
    "        reg = LinearRegression().fit(predictors, grid_train)\n",
    "        fore = reg.predict(predictors_test)\n",
    "        mae_log[i, j] = np.mean(abs(fore - grid_test))\n",
    "        j = j+1\n",
    "    i = i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
